I"P
<p>E-PCA is a non-linear dimensionality reduction technique particularly suited
to probability distributions, see the paper <a href="http://www.cs.cmu.edu/~ggordon/nickr-ggordon.nips02.pdf">Exponential Family PCA for Belief Compression
in POMDPs</a>.</p>

<ul>
  <li><a href="https://github.com/gpldecha/e-pca">Matlab implementation of E-PCA</a>.</li>
</ul>

<p>The left figure illustrates a filtered 2D probability distribution of an agent&#8217;s location in a square world with a red block (goal state) at its center. The right figure is the result of the probability density function being reconstructed after a latent lower dimensional space was leaned via E-PCA.</p>

<p><img src="https://gpldecha.github.io/images//projects/e_pca/original_belief.gif" alt="Original beliefs" align="middle" /></p>

<p><img src="https://gpldecha.github.io/images//projects/e_pca/reconstructed_belief.gif" alt="Reconstructed beliefs" align="middle" /></p>

<p>In the above animation the original dimension of the probability distribution is 625 and the learned E-PCA latent space
has 8 dimensions. This is a very large compression, we went from 625 dimensions to 8 and as we can see the reconstructed probability distributions (right) are very similar to the original distributions (left).</p>

<p>The optimisation to find the latent space feature space is convex and can be solved though Newton&#8217;s methods. The matalab implementation follows closely the aglorithm details given in the paper <a href="https://arxiv.org/pdf/1107.0053.pdf">Finding Approximate POMDP Solutions Through Belief
Compression</a>, see page 14.</p>
:EF